{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blgayatri/DS_Projects/blob/main/Multiclass_Fish_Image_Classification_ML_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Multiclass Fish Image Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Deep Learning - Image Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Lakshmi Gayatri Balivada"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project was to develop a deep learning model capable of classifying images of fish into multiple species using Convolutional Neural Networks (CNNs). The dataset used contained 6,225 images belonging to 11 distinct classes. The images varied in resolution and were resized to 224×224 pixels for uniform processing. The dataset was split into training, validation, and testing sets to evaluate the model’s performance effectively.\n",
        "\n",
        "To begin, the dataset was mounted from Google Drive and extracted in Google Colab. Data preprocessing included image rescaling to normalize pixel values between 0 and 1, as well as augmentation techniques such as rotation, zooming, and horizontal flipping to enhance model generalization and reduce overfitting.\n",
        "\n",
        "A CNN model was implemented with multiple convolutional, pooling, and dropout layers, followed by a fully connected layer and a softmax output layer for multiclass classification. The model was trained for 10 epochs using the Adam optimizer and categorical crossentropy loss function. Training progress was monitored using accuracy and loss plots, while the final performance was evaluated on the validation and test datasets.\n",
        "\n",
        "The results demonstrated that the model achieved promising accuracy on unseen test data, showing a good ability to differentiate between fish species. A confusion matrix and classification report provided insights into class-wise performance. Although the model performed well, there is potential for further improvement using advanced architectures like ResNet50, EfficientNet, or MobileNetV2, as well as hyperparameter tuning and dataset expansion.\n",
        "\n",
        "In conclusion, this project highlights the effectiveness of CNN-based deep learning in solving multiclass image classification problems. With additional optimization, such a system could be highly valuable in applications such as fisheries management, marine biodiversity studies, and automated ecological monitoring."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to develop a machine learning model capable of accurately classifying images of different fish species. With increasing concerns about marine biodiversity and the need for efficient monitoring of aquatic ecosystems, automated fish species identification can greatly assist researchers, conservationists, and fisheries management. This project aims to use deep learning techniques, particularly convolutional neural networks (CNNs), to build a robust classifier that can distinguish between multiple fish classes from input images. The model’s performance will be evaluated using standard metrics such as accuracy, precision, recall, and F1-score. Ultimately, the classifier will be deployed in a user-friendly interface to facilitate practical usage."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# ***1. Setup & Project Initialization***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Install Required Libraries (run in terminal)***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Mount Google Drive & Extract Dataset"
      ],
      "metadata": {
        "id": "Lhz0ahhAsK0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "5sQxhdPvvOb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os, zipfile\n",
        "\n",
        "# 1️⃣ Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Go to your folder and check the exact filename\n",
        "folder_path = \"/content/drive/My Drive/Data Science/Projects/Multiclass Fish Image Classification\"\n",
        "print(os.listdir(folder_path))  # Look for the .zip file name here\n",
        "\n",
        "# 3️⃣ Once you see the exact name, update this line:\n",
        "zip_path = os.path.join(folder_path, \"Dataset.zip\")\n",
        "extract_path = \"/content/drive/My Drive/Data Science/Projects/Multiclass Fish Image Classification/images.cv_jzk6llhf18tm3k0kyttxz\"\n",
        "\n",
        "# 4️⃣ Extract the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Files extracted to:\", extract_path)"
      ],
      "metadata": {
        "id": "OUpgWWNJ15wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# ✅ Correct base path\n",
        "base_path = \"/content/drive/My Drive/Data Science/Projects/Multiclass Fish Image Classification/images.cv_jzk6llhf18tm3k0kyttxz/data\"\n",
        "\n",
        "train_dir = os.path.join(base_path, \"train\")\n",
        "val_dir = os.path.join(base_path, \"val\")\n",
        "test_dir = os.path.join(base_path, \"test\")\n",
        "\n",
        "# ✅ Image size and batch\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# ✅ Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# ✅ No augmentation for validation/test\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ Data generators\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ Class names\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "print(\"Classes:\", class_names)"
      ],
      "metadata": {
        "id": "XCO1yVJNn3wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Base dataset folder\n",
        "base_path = \"/content/drive/My Drive/Data Science/Projects/Multiclass Fish Image Classification/images.cv_jzk6llhf18tm3k0kyttxz/data\"\n",
        "\n",
        "# Define paths for train, val, and test\n",
        "train_dir = os.path.join(base_path, \"train\")\n",
        "val_dir = os.path.join(base_path, \"val\")\n",
        "test_dir = os.path.join(base_path, \"test\")\n",
        "\n",
        "print(\"Train dir exists:\", os.path.exists(train_dir))\n",
        "print(\"Val dir exists:\", os.path.exists(val_dir))\n",
        "print(\"Test dir exists:\", os.path.exists(test_dir))\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. CNN Model\n",
        "\n"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Training data generator with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Validation & test data generator (no augmentation)\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Save class names for later use\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "print(\"Class names:\", class_names)"
      ],
      "metadata": {
        "id": "4g4tlrQjtyQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Input shape & number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "prhCQk58tFw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model Evaluation and Performance Evaluation"
      ],
      "metadata": {
        "id": "g9G9837ktumQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Plot accuracy & loss curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lyjeaeBKuB7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Data Preprocessing & Augmentation"
      ],
      "metadata": {
        "id": "Cp769u4ysa3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predictions on test data\n",
        "pred_probs = model.predict(test_gen)\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# True labels\n",
        "true_classes = test_gen.classes\n",
        "class_labels = list(test_gen.class_indices.keys())\n",
        "\n",
        "# Plot a few predictions\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(9):\n",
        "    img, label = test_gen[i]  # get a batch\n",
        "    for j in range(3):  # pick 3 images from the batch\n",
        "        idx = i * test_gen.batch_size + j\n",
        "        plt.subplot(3, 3, j + 1)\n",
        "        plt.imshow(img[j])\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Pred: {class_labels[pred_classes[idx]]}\\nTrue: {class_labels[label[j].argmax()]}\")\n",
        "    break  # only first batch\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CA3zDXw1oCEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions on the test set\n",
        "predictions = model.predict(test_gen, verbose=1)\n",
        "\n",
        "# Now proceed to evaluation\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_gen.classes\n",
        "labels = list(test_gen.class_indices.keys())\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n-0WlKO-opOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Build CNN Model"
      ],
      "metadata": {
        "id": "_3rQcsgDtK7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Get some random indices from test set\n",
        "random_indices = random.sample(range(len(test_gen.filenames)), 9)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    img_path = test_gen.filepaths[idx]\n",
        "    img = image.load_img(img_path, target_size=img_size)\n",
        "    img_array = image.img_to_array(img) / 255.0  # normalize\n",
        "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(img_array_expanded, verbose=0)\n",
        "    pred_class = class_names[np.argmax(pred)]\n",
        "    true_class = class_names[test_gen.classes[idx]]\n",
        "\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img_array)\n",
        "    plt.title(f\"Pred: {pred_class}\\nTrue: {true_class}\", color=(\"green\" if pred_class == true_class else \"red\"))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Sample Predictions from Test Set\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8IkOyKX0qMed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "model.save(\"/content/fish_species_classifier.h5\")\n",
        "\n",
        "# (Optional) Save just weights\n",
        "# model.save_weights(\"/content/fish_species_weights.h5\")\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "G66N_wNfqeDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model(\"/content/fish_species_classifier.h5\")\n"
      ],
      "metadata": {
        "id": "BxG3nu0Tqk15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Work Done:\n",
        "\n",
        "* Built a CNN-based Multi-class Fish Species Classifier using TensorFlow/Keras.\n",
        "\n",
        "* Used data augmentation to improve generalization.\n",
        "\n",
        "* Achieved an accuracy of <INSERT_ACCURACY> on the validation set.\n",
        "\n",
        "* Evaluated the model with a classification report and confusion matrix.\n",
        "\n",
        "Challenges Faced:\n",
        "\n",
        "* Dataset imbalance for certain classes.\n",
        "\n",
        "* Possible overfitting on training data.\n",
        "\n",
        "Future Improvements:\n",
        "\n",
        "* Experiment with deeper architectures like ResNet50, EfficientNet, or MobileNetV2.\n",
        "\n",
        "* Use Transfer Learning to improve accuracy.\n",
        "\n",
        "* Increase dataset size by adding more fish species images.\n",
        "\n",
        "* Deploy as a web app using Streamlit or Flask."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}